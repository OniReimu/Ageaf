#!/usr/bin/env node

import { createInterface } from "node:readline";

function write(value) {
  process.stdout.write(`${JSON.stringify(value)}\n`);
}

function hasOwn(value, key) {
  return (
    value &&
    typeof value === "object" &&
    Object.prototype.hasOwnProperty.call(value, key)
  );
}

function requireKeys(value, keys) {
  return keys.every((key) => hasOwn(value, key));
}

const args = process.argv.slice(2);
if (args.includes("--version")) {
  process.stdout.write("0.0.0-test\n");
  process.exit(0);
}

if (args[0] !== "app-server") {
  process.stderr.write(`Unknown args: ${args.join(" ")}\n`);
  process.exit(1);
}

const rl = createInterface({ input: process.stdin, crlfDelay: Infinity });
let nextThread = 0;
const knownThreads = new Set();
let savedConfig = {
  model: "gpt-5.2-codex",
  modelReasoningEffort: "low",
};
const availableModels = [
  {
    id: "model-1",
    model: "gpt-5.2-codex",
    displayName: "gpt-5.2-codex",
    description: "Test Codex model",
    supportedReasoningEfforts: [
      { reasoningEffort: "none", description: "No extra reasoning" },
      { reasoningEffort: "low", description: "Low reasoning" },
      { reasoningEffort: "medium", description: "Medium reasoning" },
      { reasoningEffort: "high", description: "High reasoning" },
    ],
    defaultReasoningEffort: "low",
    isDefault: true,
  },
];

rl.on("line", (line) => {
  let msg;
  try {
    msg = JSON.parse(line);
  } catch {
    return;
  }

  if (!msg || typeof msg !== "object") return;

  if (msg.id && msg.method === "initialize") {
    write({ id: msg.id, result: { ok: true } });
    return;
  }

  if (msg.method === "initialized") {
    return;
  }

  if (msg.id && msg.method === "getUserSavedConfig") {
    write({ id: msg.id, result: { config: savedConfig } });
    return;
  }

  if (msg.id && msg.method === "setDefaultModel") {
    const nextModel = typeof msg.params?.model === "string" ? msg.params.model : null;
    const nextEffort =
      typeof msg.params?.reasoningEffort === "string" ? msg.params.reasoningEffort : null;
    if (nextModel) savedConfig.model = nextModel;
    if (nextEffort) savedConfig.modelReasoningEffort = nextEffort;
    write({ id: msg.id, result: {} });
    return;
  }

  if (msg.id && msg.method === "model/list") {
    const required = ["cursor", "limit"];
    if (!requireKeys(msg.params, required)) {
      write({ id: msg.id, error: { message: "invalid model/list params" } });
      return;
    }
    write({ id: msg.id, result: { data: availableModels, nextCursor: null } });
    return;
  }

  if (msg.id && msg.method === "thread/start") {
    const required = [
      "model",
      "modelProvider",
      "cwd",
      "approvalPolicy",
      "sandbox",
      "config",
      "baseInstructions",
      "developerInstructions",
      "experimentalRawEvents",
    ];
    if (!requireKeys(msg.params, required)) {
      write({ id: msg.id, error: { message: "invalid thread/start params" } });
      return;
    }
    nextThread += 1;
    const threadId = `thread-${nextThread}`;
    knownThreads.add(threadId);
    write({ id: msg.id, result: { thread: { id: threadId } } });
    return;
  }

  if (msg.id && msg.method === "turn/start") {
    const required = [
      "threadId",
      "input",
      "cwd",
      "approvalPolicy",
      "sandboxPolicy",
      "model",
      "effort",
      "summary",
      "outputSchema",
      "collaborationMode",
    ];
    if (!requireKeys(msg.params, required)) {
      const threadId = msg.params?.threadId ?? msg.params?.thread_id ?? "thread-1";
      const turnId = "turn-invalid-params";
      write({ id: msg.id, error: { message: "invalid turn/start params" } });
      write({
        method: "error",
        params: {
          threadId,
          turnId,
          error: { message: "invalid turn/start params" },
          willRetry: false,
        },
      });
      write({ method: "turn/completed", params: { threadId, turn: { id: turnId } } });
      return;
    }
    const threadId = msg.params?.threadId ?? msg.params?.thread_id ?? "thread-1";
    if (!knownThreads.has(threadId)) {
      const turnId = "turn-unknown-thread";
      write({ id: msg.id, error: { message: "unknown threadId" } });
      write({
        method: "error",
        params: {
          threadId,
          turnId,
          error: { message: "unknown threadId" },
          willRetry: false,
        },
      });
      write({ method: "turn/completed", params: { threadId, turn: { id: turnId } } });
      return;
    }
    const turnId = "turn-1";
    const model = typeof msg.params?.model === "string" ? msg.params.model : null;
    const effort = typeof msg.params?.effort === "string" ? msg.params.effort : null;
    const fullText = `Hello from Codex [model=${model ?? "null"} effort=${effort ?? "null"}]`;
    write({ id: msg.id, result: { ok: true } });
    write({ method: "turn/started", params: { threadId, turn: { id: turnId } } });

    write({
      method: "item/agentMessage/delta",
      params: { threadId, itemId: "item-1", delta: "Hello from Codex" },
    });
    write({
      method: "item/agentMessage/delta",
      params: { threadId, itemId: "item-1", delta: ` [model=${model ?? "null"} effort=${effort ?? "null"}]` },
    });
    // Some Codex builds also deliver the full assistant output via item/completed.
    write({
      method: "item/completed",
      params: {
        threadId,
        item: { role: "assistant", content: fullText },
      },
    });
    write({
      method: "thread/tokenUsage/updated",
      params: {
        threadId,
        tokenUsage: {
          total: { totalTokens: 22 },
          modelContextWindow: 200000,
        },
      },
    });
    write({ method: "turn/completed", params: { threadId, turn: { id: turnId } } });
    return;
  }

  if (msg.id) {
    write({ id: msg.id, result: { ok: true } });
  }
});

